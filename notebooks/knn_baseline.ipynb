{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbd44219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jme3qd/.conda/envs/dsvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from torch.utils.data import Subset\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import silhouette_score\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db58113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_image_nxn(img, tiles_per_side=3, target_size=518):\n",
    "    w, h = img.size\n",
    "\n",
    "    tile_w = w / tiles_per_side\n",
    "    tile_h = h / tiles_per_side\n",
    "\n",
    "    tiles = []\n",
    "\n",
    "    for row in range(tiles_per_side):\n",
    "        for col in range(tiles_per_side):\n",
    "            left = int(col * tile_w)\n",
    "            top = int(row * tile_h)\n",
    "            right = int((col + 1) * tile_w)\n",
    "            bottom = int((row + 1) * tile_h)\n",
    "\n",
    "            tile = img.crop((left, top, right, bottom))\n",
    "            tile = tile.resize((target_size, target_size), Image.BICUBIC)\n",
    "            tiles.append(tile)\n",
    "\n",
    "    return tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f65f9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225)\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8cd29bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadratNxNDataset(Dataset):\n",
    "    def __init__(self, root, transform, tiles_per_side=3, target_size=518):\n",
    "        self.paths = sorted([str(p) for p in Path(root).glob(\"*.*\")])\n",
    "        self.transform = transform\n",
    "        self.tiles_per_side = tiles_per_side\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "        tiles = tile_image_nxn(\n",
    "            img,\n",
    "            tiles_per_side=self.tiles_per_side,\n",
    "            target_size=self.target_size\n",
    "        )\n",
    "\n",
    "        tiles = [self.transform(t) for t in tiles]\n",
    "        tiles = torch.stack(tiles)  # shape [N*N, 3, 518, 518]\n",
    "\n",
    "        return tiles, path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e865e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jme3qd/.conda/envs/dsvenv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.ImageFolder(\"/scratch/jme3qd/data/plantclef2025/images_max_side_800\", transform=transform)\n",
    "\n",
    "n_samples = 20000\n",
    "indices = np.random.choice(len(train_dataset), n_samples, replace=False)\n",
    "train_subset = Subset(train_dataset, indices)\n",
    "\n",
    "# %%\n",
    "#train_loader = DataLoader(train_subset, batch_size=32, shuffle=False, num_workers=4)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decdcd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "quadrat_path = \"/scratch/jme3qd/data/plantclef2025/data/PlantCLEF/PlantCLEF2025/DataOut/test/package/images\"\n",
    "\n",
    "quadrat_loader = DataLoader(\n",
    "    QuadratNxNDataset(\n",
    "        quadrat_path,\n",
    "        transform,\n",
    "        tiles_per_side=5,\n",
    "        target_size=518\n",
    "    ),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90257e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = timm.create_model(\"timm/vit_base_patch14_reg4_dinov2.lvd142m\", pretrained=True)\n",
    "#model = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "checkpoint_path = '/home/jme3qd/Downloads/model_best.pth.tar'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False) # Load to CPU first\n",
    "\n",
    "if 'state_dict' in checkpoint:\n",
    "    state_dict = checkpoint['state_dict']\n",
    "else:\n",
    "    state_dict = checkpoint # Assume the checkpoint itself is the state_dict\n",
    "\n",
    "# 3. Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict,strict=False)\n",
    "\n",
    "model.eval().to(device)\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f4d3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings loaded from slurm/embs_train.npz\n"
     ]
    }
   ],
   "source": [
    "def extract_embeddings(dataloader):\n",
    "    all_embs, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(dataloader):\n",
    "            imgs = imgs.to(device)\n",
    "            feats = model.forward_features(imgs)\n",
    "            if feats.ndim == 3:\n",
    "                cls_embs = feats[:, 0, :]  # [CLS] token\n",
    "            else:\n",
    "                cls_embs = feats\n",
    "            all_embs.append(cls_embs.cpu().numpy())\n",
    "            all_labels.append(labels.numpy())\n",
    "    return np.concatenate(all_embs), np.concatenate(all_labels)\n",
    "\n",
    "train_file = \"slurm/embs_train.npz\"\n",
    "if os.path.exists(train_file):\n",
    "    with np.load(train_file) as data:\n",
    "        train_embs = data['embs']\n",
    "        train_labels = data['labels']\n",
    "        print(\"Train embeddings loaded from\", train_file)\n",
    "else:\n",
    "    train_embs, train_labels = extract_embeddings(train_loader)\n",
    "    np.savez(train_file, embs=train_embs, labels=train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e79edca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2105/2105 [59:16<00:00,  1.69s/it] \n"
     ]
    }
   ],
   "source": [
    "def extract_unlabeled_embeddings(dataloader, model, device):\n",
    "    all_embs, all_paths = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "\n",
    "            imgs = batch[0]      # shape (B, T, 3, 518, 518)\n",
    "            paths = batch[1]     # list of length B\n",
    "\n",
    "            # Flatten tiles:\n",
    "            # imgs: (B, T, C, H, W) → (B*T, C, H, W)\n",
    "            B, T, C, H, W = imgs.shape\n",
    "            imgs = imgs.view(B * T, C, H, W).to(device)\n",
    "\n",
    "            feats = model.forward_features(imgs)\n",
    "            cls_embs = feats[:, 0, :] if feats.ndim == 3 else feats\n",
    "\n",
    "            # Save embeddings\n",
    "            all_embs.append(cls_embs.cpu().numpy())\n",
    "\n",
    "            # Save one path for every tile\n",
    "            # If image X has 25 tiles → repeat the path 25 times\n",
    "            for p in paths:\n",
    "                all_paths.extend([p] * T)\n",
    "\n",
    "    return np.concatenate(all_embs), all_paths\n",
    "\n",
    "\n",
    "filename = \"slurm/quadrat_embs_5x5.npz\"\n",
    "if os.path.exists(filename):\n",
    "    with np.load(filename) as data:\n",
    "        quadrat_embs = data['embs']\n",
    "        quadrat_paths = data['paths']\n",
    "        print(\"Quadrat embeddings loaded from\", filename)\n",
    "else:\n",
    "    quadrat_embs, quadrat_paths = extract_unlabeled_embeddings(quadrat_loader, model, device)\n",
    "    np.savez(filename, embs=quadrat_embs, paths=quadrat_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b17e42ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgs shape: torch.Size([1, 25, 3, 518, 518])\n",
      "first meta item: /scratch/jme3qd/data/plantclef2025/data/PlantCLEF/PlantCLEF2025/DataOut/test/package/images/2024-CEV3-20240602.jpg\n",
      "type of meta item: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(quadrat_loader))\n",
    "imgs = batch[0]\n",
    "meta = batch[1]\n",
    "\n",
    "print(\"imgs shape:\", imgs.shape)\n",
    "print(\"first meta item:\", meta[0])\n",
    "print(\"type of meta item:\", type(meta[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.normalize_L2(quadrat_embs)\n",
    "faiss.normalize_L2(train_embs)\n",
    "index = faiss.IndexFlatIP(train_embs.shape[1])\n",
    "index.add(train_embs)\n",
    "D, I = index.search(quadrat_embs, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536241ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2105 [00:00<?, ?it/s]/home/jme3qd/.conda/envs/dsvenv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "  6%|▌         | 126/2105 [08:08<2:07:48,  3.87s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_769126/1666243462.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     11\u001b[39m         feats = model.forward_features(tiles)\n\u001b[32m     12\u001b[39m         cls = feats[:, \u001b[32m0\u001b[39m, :].cpu().numpy()\n\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m         k = \u001b[32m5\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m         distances, indices = index.search(cls, k)\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m         tile_labels = train_labels[indices]\n\u001b[32m     18\u001b[39m         quadrat_tile_predictions[path] = tile_labels\n",
      "\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/faiss/class_wrappers.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, x, k, params, D, I, numeric_type)\u001b[39m\n\u001b[32m    360\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m             \u001b[38;5;28;01massert\u001b[39;00m I.shape == (n, k)\n\u001b[32m    362\u001b[39m \n\u001b[32m    363\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m numeric_type == faiss.Float32:\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m             self.search_c(n, swig_ptr(x), k, swig_ptr(D), swig_ptr(I), params)\n\u001b[32m    365\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    366\u001b[39m             self.searchEx(n, swig_ptr(x), numeric_type, k, swig_ptr(D), swig_ptr(I), params)\n\u001b[32m    367\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m D, I\n",
      "\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/faiss/swigfaiss.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, n, x, k, distances, labels, params)\u001b[39m\n\u001b[32m   3197\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m search(self, n, x, k, distances, labels, params=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m3198\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _swigfaiss.IndexFlat_search(self, n, x, k, distances, labels, params)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "quadrat_tile_predictions = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tiles, path in tqdm(quadrat_loader):\n",
    "        path = path[0]\n",
    "        tiles = tiles.to(device)\n",
    "\n",
    "        T = tiles.shape[1]\n",
    "        tiles = tiles.view(T, 3, 518, 518)\n",
    "\n",
    "        feats = model.forward_features(tiles)\n",
    "        cls = feats[:, 0, :].cpu().numpy()\n",
    "\n",
    "        k = 5\n",
    "        distances, indices = index.search(cls, k)\n",
    "\n",
    "        tile_labels = train_labels[indices]\n",
    "        quadrat_tile_predictions[path] = tile_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d34941",
   "metadata": {},
   "outputs": [],
   "source": [
    "quadrat_final_predictions = {}\n",
    "\n",
    "for path, tile_knn_labels in quadrat_tile_predictions.items():\n",
    "    flat = tile_knn_labels.flatten()\n",
    "    counts = Counter(flat)\n",
    "\n",
    "    total_votes = len(flat)\n",
    "    threshold = 0.05 * total_votes\n",
    "\n",
    "    preds = [s for s, c in counts.items() if c >= threshold]\n",
    "    quadrat_final_predictions[path] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5856f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"submission.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"quadrat_id\", \"species_ids\"])\n",
    "\n",
    "    for path, species_list in quadrat_final_predictions.items():\n",
    "        quadrat_id = Path(path).stem  # filename without extension\n",
    "\n",
    "        # Convert list → \"[1, 2, 3]\"\n",
    "        species_str = \"[\" + \", \".join(str(s) for s in species_list) + \"]\"\n",
    "\n",
    "        writer.writerow([quadrat_id, species_str])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b83d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m silhouette_score\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m sil_score = \u001b[43msilhouette_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_embs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcosine\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSilhouette score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msil_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/metrics/cluster/_unsupervised.py:138\u001b[39m, in \u001b[36msilhouette_score\u001b[39m\u001b[34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[39m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    137\u001b[39m         X, labels = X[indices], labels[indices]\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np.mean(\u001b[43msilhouette_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/metrics/cluster/_unsupervised.py:302\u001b[39m, in \u001b[36msilhouette_samples\u001b[39m\u001b[34m(X, labels, metric, **kwds)\u001b[39m\n\u001b[32m    298\u001b[39m kwds[\u001b[33m\"\u001b[39m\u001b[33mmetric\u001b[39m\u001b[33m\"\u001b[39m] = metric\n\u001b[32m    299\u001b[39m reduce_func = functools.partial(\n\u001b[32m    300\u001b[39m     _silhouette_reduce, labels=labels, label_freqs=label_freqs\n\u001b[32m    301\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m results = \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    303\u001b[39m intra_clust_dists, inter_clust_dists = results\n\u001b[32m    304\u001b[39m intra_clust_dists = np.concatenate(intra_clust_dists)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:2240\u001b[39m, in \u001b[36mpairwise_distances_chunked\u001b[39m\u001b[34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[39m\n\u001b[32m   2238\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2239\u001b[39m     X_chunk = X[sl]\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m D_chunk = \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[32m   2242\u001b[39m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2243\u001b[39m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[32m   2244\u001b[39m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[32m   2245\u001b[39m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[32m   2246\u001b[39m     D_chunk.flat[sl.start :: _num_samples(X) + \u001b[32m1\u001b[39m] = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:2476\u001b[39m, in \u001b[36mpairwise_distances\u001b[39m\u001b[34m(X, Y, metric, n_jobs, force_all_finite, ensure_all_finite, **kwds)\u001b[39m\n\u001b[32m   2473\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m distance.squareform(distance.pdist(X, metric=metric, **kwds))\n\u001b[32m   2474\u001b[39m     func = partial(distance.cdist, metric=metric, **kwds)\n\u001b[32m-> \u001b[39m\u001b[32m2476\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:1960\u001b[39m, in \u001b[36m_parallel_pairwise\u001b[39m\u001b[34m(X, Y, func, n_jobs, **kwds)\u001b[39m\n\u001b[32m   1957\u001b[39m X, Y, dtype = _return_float_dtype(X, Y)\n\u001b[32m   1959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) == \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1960\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1962\u001b[39m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[32m   1963\u001b[39m fd = delayed(_dist_wrapper)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:1167\u001b[39m, in \u001b[36mcosine_distances\u001b[39m\u001b[34m(X, Y)\u001b[39m\n\u001b[32m   1164\u001b[39m xp, _ = get_namespace(X, Y)\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m# 1.0 - cosine_similarity(X, Y) without copy\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m S = \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1168\u001b[39m S *= -\u001b[32m1\u001b[39m\n\u001b[32m   1169\u001b[39m S += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:1736\u001b[39m, in \u001b[36mcosine_similarity\u001b[39m\u001b[34m(X, Y, dense_output)\u001b[39m\n\u001b[32m   1733\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1734\u001b[39m     Y_normalized = normalize(Y, copy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m K = \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/sklearn/utils/extmath.py:206\u001b[39m, in \u001b[36msafe_sparse_dot\u001b[39m\u001b[34m(a, b, dense_output)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    203\u001b[39m     ret = a @ b\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     \u001b[43msparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m sparse.issparse(b)\n\u001b[32m    208\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[32m    209\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[33m\"\u001b[39m\u001b[33mtoarray\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    210\u001b[39m ):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.toarray()\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/dsvenv/lib/python3.12/site-packages/scipy/sparse/_base.py:1388\u001b[39m, in \u001b[36missparse\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1382\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"A namespace class to separate sparray from spmatrix\"\"\"\u001b[39;00m\n\u001b[32m   1385\u001b[39m sparray.\u001b[34m__doc__\u001b[39m = _spbase.\u001b[34m__doc__\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34missparse\u001b[39m(x):\n\u001b[32m   1389\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Is `x` of a sparse array or sparse matrix type?\u001b[39;00m\n\u001b[32m   1390\u001b[39m \n\u001b[32m   1391\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1417\u001b[39m \u001b[33;03m    False\u001b[39;00m\n\u001b[32m   1418\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _spbase)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "sil_score = silhouette_score(train_embs, train_labels, metric='cosine')\n",
    "print(f\"Silhouette score: {sil_score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50839c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "D_train, I_train = index.search(train_embs, k=5)\n",
    "purity = np.mean([\n",
    "    np.mean(train_labels[i] == train_labels[nbrs]) \n",
    "    for i, nbrs in enumerate(I_train)\n",
    "])\n",
    "print(f\"Neighborhood purity (k=5): {purity:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5b6042",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "idx = random.randint(0, len(quadrat_paths)-1)\n",
    "nbrs = I[idx]\n",
    "fig, axes = plt.subplots(1, k+1, figsize=(15, 4))\n",
    "axes[0].imshow(Image.open(quadrat_paths[idx]))\n",
    "axes[0].set_title(\"Quadrat tile\")\n",
    "for j, n in enumerate(nbrs):\n",
    "    axes[j+1].imshow(Image.open(train_dataset.samples[n][0]))\n",
    "    axes[j+1].set_title(train_dataset.classes[train_labels[n]])\n",
    "plt.savefig(f\"quadrat_{idx}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
